# Awesome-Robotics


---

<font size=5><center><b> Table of Contents </b> </center></font>
- [Awesome Papers](#awesome-papers)
- - [Awesome Suvey](#Awesome-Suvey)
  - [Awesome Robot Learning](#Awesome-Robot-Learning)
  - [Awesome Imitation Learning](#Awesome-Imitation-Learning)
  - [Awesome Vision](#Awesome-Vision)
  - [Awesome Teleoperation](#Awesome-Teleoperation)
  - [Awesome Humanoid locomotion](#Awesome-locomotion)
  - [Awesome Touch](#Awesome-Touch)
  - [Awesome Data](#Awesome-Data)


- [Awesome Reference](#awesome-reference-source)
  - [Awesome Books](#Awesome-books)
  - [Awesome Source](#Awesome-source)
---

# Awesome Papers

## Awesome Suvey
|  Title  |   Venue  |   Date   |   Code / Info   |   Demo   |
|:--------|:--------:|:--------:|:--------:|:--------:|
| <br> [**Humanoid Locomotion and Manipulation: Current Progress and Challenges in Control, Planning, and Learning**](https://arxiv.org/abs/2501.02116) <br> | arVix  | 2025-01 |  |  |

## Awesome Robot Learning
|  Title  |   Venue  |   Date   |   Code / Info   |   Demo   |
|:--------|:--------:|:--------:|:--------:|:--------:|
| <br> [**ConRFT: A Reinforced Fine-tuning Method for VLA Models via Consistency Policy**](https://cccedric.github.io/conrft/) <br> | RSS  | 2025 | [Code](https://github.com/cccedric/conrft) |  |
| <br> [**TokenHSI: Unified Synthesis of Physical Human-Scene Interactions through Task Tokenization**](https://liangpan99.github.io/TokenHSI/) <br> | CVPR  | 2025 | [Code](https://github.com/liangpan99/TokenHSI) |  |
| <br> [**AgiBot World Colosseo: A Large-scale Manipulation Platform for Scalable and Intelligent Embodied Systems**](https://agibot-world.com/) <br> | arVix  | 2025 | [Code](https://github.com/OpenDriveLab/AgiBot-World) |  |
| <br> [**π0: A Vision-Language-Action Flow Model for General Robot Control**](https://www.physicalintelligence.company/blog/pi0) <br> | arVix  | 2024 | [Code](https://github.com/allenzren/open-pi-zero) |  |
| <br> [**INTERMIMIC: Towards Universal Whole-Body Control for Physics-Based Human-Object Interactions**](https://arxiv.org/pdf/2502.20390) <br> | CVPR  | 2025 | [Code](https://github.com/Sirui-Xu/InterMimic) |  |
| <br> [**Controllable Human-Object Interaction Synthesis**](https://lijiaman.github.io/projects/chois/) <br> | ECCV  | 2024 | [Code](https://github.com/lijiaman/chois_release) |  |
| <br> [**Human-Object Interaction from Human-Level Instructions**](https://hoifhli.github.io/) <br> | arVix  | 2024-12 |  |  |
| <br> [**CogACT: A Foundational Vision-Language-Action Model for Synergizing Cognition and Action in Robotic Manipulation**](https://cogact.github.io/) <br> | arXiv  | 2024-11 | [Code](https://github.com/microsoft/CogACT/tree/main) |  |
| <br> [**Visual Whole-Body Control for Legged Loco-Manipulation**](https://wholebody-b1.github.io/) <br> | CoRL | 2024-11-02 | [Code](https://github.com/Ericonaldo/visual_wholebody)  |  |
| <br> [**OK-Robot: What Really Matters in Integrating Open-Knowledge Models for Robotics**](https://ok-robot.github.io/) <br> | CoRL | 2024-02-29 | [Code](https://github.com/ok-robot/ok-robot)  |  |
| <br> [**OKAMI: Teaching Humanoid Robots Manipulation Skills through Single Video Imitation**](https://ut-austin-rpl.github.io/OKAMI/) <br> | CoRL 2024 | 2024-09 |  |  |
| <br> [**CooHOI: Learning Cooperative Human-Object Interaction with Manipulated Object Dynamics**](https://gao-jiawei.com/Research/CooHOI/) <br> | NeurIPS 2024 | 2024-10 | [Code](https://gao-jiawei.com/Research/CooHOI/) |  |
| <br> [**ControlVAE: Model-Based Learning of Generative Controllers for Physics-Based Characters**](https://heyuanyao-pku.github.io/Control-VAE/) <br> | SIGGRAPH Asia  | 2022| [Code](https://github.com/heyuanYao-pku/Control-VAE) |  |
| <br> [**PhysHOI: Physics-Based Imitation of Dynamic Human-Object Interaction**](https://wyhuai.github.io/physhoi-page/) <br> | arXiv  | 2024-10 | [Code](https://github.com/wyhuai/PhysHOI/tree/main) |  |
| <br> [**SkillMimic: Learning Reusable Basketball Skills from Demonstrations**](https://ingrid789.github.io/SkillMimic/) <br> | CVPR  | 2024-08 | [Code](https://github.com/wyhuai/SkillMimic) |  |
| <br> [**Humanoid Policy ~ Human Policy**](https://human-as-robot.github.io/) <br> | arVix  | 2025| [Code](https://github.com/RogerQi/human-policy) |  |

## Awesome Imitation Learning
|  Title  |   Venue  |   Date   |   Code / Info   |   Demo   |
|:--------|:--------:|:--------:|:--------:|:--------:|
| <br> [**DeepMimic: Example-Guided Deep Reinforcement Learning of Physics-Based Character Skills**](https://xbpeng.github.io/projects/DeepMimic/index.html) <br> | ACM SIGGRAPH 2018 | 2024-05-22 | [Code](https://github.com/xbpeng/DeepMimic/tree/master)  |  |
| <br> [**AMP: Adversarial Motion Priors for Stylized Physics-Based Character Control**](https://xbpeng.github.io/projects/AMP/index.html) <br> | ACM SIGGRAPH 2021 | 2024-05-22 | [Code1](https://github.com/Alescontrela/AMP_for_hardware) [Code2](https://github.com/nv-tlabs/ASE/tree/main)   |  |
| <br> [**ASE: Large-Scale Reusable Adversarial Skill Embeddings for Physically Simulated Characters**](https://xbpeng.github.io/projects/ASE/index.html) <br> | ACM SIGGRAPH 2022 | 2024-05-22 | [Code](https://github.com/nv-tlabs/ASE/tree/main)  |  |
| <br> [**PMP: Learning to Physically Interact with Environments using Part-wise Motion Priors**](https://github.com/jinseokbae/pmp) <br> | SIGGRAPH 2023 | 2023-05 |  |  |
| <br> [**C·ASE: Learning Conditional Adversarial Skill Embeddings for Physics-based Characters**](https://frank-zy-dou.github.io/projects/CASE/index.html) <br> | SIGGRAPH ASIA 2023 | 2023-09 |  |  |
| <br> [**Synthesizing Physical Character-Scene Interactions**](https://research.nvidia.com/publication/2023-08_synthesizing-physical-character-scene-interactions) <br> | SIGGRAPH 2023 | 2023-02 |  |  |
| <br> [**MaskedMimic: Unified Physics-Based Character Control Through Masked Motion Inpainting**](https://research.nvidia.com/labs/par/maskedmimic/) <br> | SIGGRAPH Asia 2024 | 2024-09 | [Code](https://github.com/NVlabs/ProtoMotions) |  |
| <br> [**Learning Physically Simulated Tennis Skills from Broadcast Videos**](https://research.nvidia.com/labs/toronto-ai/vid2player3d/) <br> | SIGGRAPH 2023 | 2023 | [Code](https://github.com/nv-tlabs/vid2player3d) |  |
| <br> [**Perpetual Humanoid Control for Real-time Simulated Avatars**](https://zhengyiluo.github.io/PHC/) <br> | ICCV  | 2023 | [Code](https://github.com/ZhengyiLuo/PHC) |  |

## Awesome Vision
|  Title  |   Venue  |   Date   |   Code / Info   |   Demo   |
|:--------|:--------:|:--------:|:--------:|:--------:|
| <br> [**HybrIK: Hybrid Analytical-Neural Inverse Kinematics for Body Mesh Recovery**](https://github.com/jeffffffli/HybrIK) <br> | CVPR 2021 | 2021 | [Code](https://github.com/jeffffffli/HybrIK)  |  |

## Awesome Teleoperation
|  Title  |   Venue  |   Date   |   Code / Info   |   Demo   |
|:--------|:--------:|:--------:|:--------:|:--------:|
| <br> [**IRIS: An Immersive Robot Interaction System**](https://arxiv.org/pdf/2502.03297) <br> | arXiv | 2025-02 |  |  |
| <br> [**Teleoperation of Humanoid Robots: A Survey**](https://arxiv.org/pdf/2301.04317) <br> | arXiv | 2023-01-11 | [Github.io](https://humanoid-teleoperation.github.io/)  |  |
| <br> [**Interactive Hand Pose Estimation using a Stretch-Sensing Soft Glove**](https://dl.acm.org/doi/pdf/10.1145/3306346.3322957) <br> | ACM Trans | 2019-07-12 |   |  |
| <br> [**Open-TeleVision: Teleoperation with Immersive Active Visual Feedback**](https://robot-tv.github.io/) <br> | CoRL | 2019-07-12 | [Code](https://github.com/OpenTeleVision/TeleVision)  |  |
| <br> [**AnyTeleop: A General Vision-Based Dexterous Robot Arm-Hand Teleoperation System**](https://yzqin.github.io/anyteleop/) <br> | RSS | 2024-05-16 | [Code](https://github.com/dexsuite/dex-retargeting)  |  |
| <br> [**OmniH2O: Universal and Dexterous Human-to-Humanoid Whole-Body Teleoperation and Learning**](https://omni.human2humanoid.com/) <br> | CoRL | 2024-01-13 | [Data](https://cmu.app.box.com/s/kmayzq5ax2rxvwn97s0hzz0aq5vws9io)  |  |
| <br> [**Learning Human-to-Humanoid Real-Time Whole-Body Teleoperation**](https://human2humanoid.com/resources/H2O_paper.pdf) <br> | IROS | 2024-01-13 | [Github.io](https://human2humanoid.com/)  |  |

## Awesome Locomotion
|  Title  |   Venue  |   Date   |   Code / Info   |   Demo   |
|:--------|:--------:|:--------:|:--------:|:--------:|
| <br> [**Advancing Humanoid Locomotion: Mastering Challenging Terrains with Denoising World Model Learning**](https://www.roboticsproceedings.org/rss20/p058.pdf) <br> | RSS | 2024-07 |  |  |
| <br> [**Humanoid-Gym: Reinforcement Learning for Humanoid Robot with Zero-Shot Sim2Real Transfer**](https://arxiv.org/pdf/2404.05695) <br> | arXiv | 2024-05-18 | [Code](https://github.com/roboterax/humanoid-gym) |  |
| <br> [**Full-Order Sampling-Based MPC for Torque-Level Locomotion Control via Diffusion-Style Annealing**](https://lecar-lab.github.io/dial-mpc/) <br> | arXiv | 2024-05-18 | [Code](https://github.com/LeCAR-Lab/dial-mpc) |  |
| <br> [**Expressive Whole-Body Control for Humanoid Robots**](https://expressive-humanoid.github.io/) <br> | RSS | 2024-03-06 | [Code](https://github.com/chengxuxin/expressive-humanoid/tree/main) |  |
| <br> [**Zero-Shot Whole-Body Humanoid Control via Behavioral Foundation Models**](https://metamotivo.metademolab.com/) <br> | arXiv  | 2024-12-12 | [Code](https://github.com/facebookresearch/metamotivo) |  |
| <br> [**ASAP: Aligning Simulation and Real-World Physics for Learning Agile Humanoid Whole-Body Skills**](https://agile.human2humanoid.com/) <br> | RSS | 2025-02 | [Code](https://github.com/LeCAR-Lab/ASAP) |  |
| <br> [**HOVER: Versatile Neural Whole-Body Controller for Humanoid Robots**](https://hover-versatile-humanoid.github.io/) <br> | ICRA | 2024-06-13 | [Code](https://github.com/NVlabs/HOVER/)   |  |

## Awesome Touch
|  Title  |   Venue  |   Date   |   Code / Info   |   Demo   |
|:--------|:--------:|:--------:|:--------:|:--------:|
| <br> [**Learning Visuotactile Skills with Two Multifingered Hands**](https://toruowo.github.io/hato/) <br> | arXiv | 2024-05-22 | [Code](https://github.com/ToruOwO/hato)  |  |

## Awesome Data
|  Title  |   Venue  |   Date   |   Code / Info   |   Demo   |
|:--------|:--------:|:--------:|:--------:|:--------:|
| <br> [**HumanoidBench: Simulated Humanoid Benchmark for Whole-Body Locomotion and Manipulation**](https://humanoid-bench.github.io/) <br> | arXiv | 2024-06 | [Code](https://github.com/carlosferrazza/humanoid-bench)  |  |
| <br> [**ParaHome: Parameterizing Everyday Home Activities Towards 3D Generative Modeling of Human-Object Interactions**](https://jlogkim.github.io/parahome/) <br> | arVix  | 2025 | [Code](https://github.com/snuvclab/ParaHome)  |  |
| <br> [**Object motion guided human motion synthesis**](https://lijiaman.github.io/projects/omomo/) <br> | SIGGRAPH Asia | 2023 | [Code](https://github.com/lijiaman/omomo_release)  |  |
| <br> [**3D-FUTURE-ToolBox**](https://arxiv.org/pdf/1906.05797) <br> |  | 2020 | [Code](https://github.com/3D-FRONT-FUTURE/3D-FUTURE-ToolBox)  |  |
| <br> [**Replica Dataset**](https://arxiv.org/pdf/1906.05797) <br> | arVix | 2019 | [Code](https://github.com/facebookresearch/Replica-Dataset)  |  |

---
# Awesome Reference Source

## Awesome Books
| Name | Link | 
|:-----|:-----:|
|<br> **Introduction to Humanoid Robotics**<br>  | [Link](https://link.springer.com/book/10.1007/978-3-642-54536-8) |

## Awesome Source
| Name | Link | 
|:-----|:-----:|
|<be> [**Spinning Up in Deep RL (OpenAI)**](https://spinningup.openai.com/en/latest/) <br> | [Github](https://github.com/openai/spinningup/tree/master) |
|<be> [**mink**](https://github.com/kevinzakka/mink/) <br> | [Github](https://github.com/kevinzakka/mink/) |
| <br> [**Demonstrating Berkeley Humanoid Lite:An Open-source, Accessible, and Customizable 3D-printed Humanoid Robot**](https://lite.berkeley-humanoid.org/) <br> |
